{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyhessian in /raid/NFS_SHARE/home/bartlomiej.krzepkowski/anaconda3/envs/fp2/lib/python3.10/site-packages (0.1)\n",
      "Requirement already satisfied: torch in /raid/NFS_SHARE/home/bartlomiej.krzepkowski/anaconda3/envs/fp2/lib/python3.10/site-packages (from pyhessian) (2.0.0)\n",
      "Requirement already satisfied: numpy in /raid/NFS_SHARE/home/bartlomiej.krzepkowski/anaconda3/envs/fp2/lib/python3.10/site-packages (from pyhessian) (1.23.5)\n",
      "Requirement already satisfied: filelock in /raid/NFS_SHARE/home/bartlomiej.krzepkowski/anaconda3/envs/fp2/lib/python3.10/site-packages (from torch->pyhessian) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /raid/NFS_SHARE/home/bartlomiej.krzepkowski/anaconda3/envs/fp2/lib/python3.10/site-packages (from torch->pyhessian) (4.4.0)\n",
      "Requirement already satisfied: sympy in /raid/NFS_SHARE/home/bartlomiej.krzepkowski/anaconda3/envs/fp2/lib/python3.10/site-packages (from torch->pyhessian) (1.11.1)\n",
      "Requirement already satisfied: networkx in /raid/NFS_SHARE/home/bartlomiej.krzepkowski/anaconda3/envs/fp2/lib/python3.10/site-packages (from torch->pyhessian) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /raid/NFS_SHARE/home/bartlomiej.krzepkowski/anaconda3/envs/fp2/lib/python3.10/site-packages (from torch->pyhessian) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /raid/NFS_SHARE/home/bartlomiej.krzepkowski/anaconda3/envs/fp2/lib/python3.10/site-packages (from jinja2->torch->pyhessian) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /raid/NFS_SHARE/home/bartlomiej.krzepkowski/anaconda3/envs/fp2/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy->torch->pyhessian) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install pyhessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pyhessian import hessian\n",
    "from pyhessian.utils import group_product, group_add, normalization, get_params_grad, hessian_vector_product, orthnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "class SimpleCNN(torch.nn.Module):\n",
    "    def __init__(self, layers_dim: List[int]):\n",
    "        super().__init__()\n",
    "        self.blocks = torch.nn.ModuleList([\n",
    "            torch.nn.Sequential(torch.nn.Conv2d(layer_dim1, layer_dim2, 3, padding=1),\n",
    "                                torch.nn.ReLU(),\n",
    "                                torch.nn.Conv2d(layer_dim2, layer_dim2, 3, padding=1, stride=2),\n",
    "                                torch.nn.ReLU(),\n",
    "                                # torch.nn.MaxPool2d(2, 2)\n",
    "                                )\n",
    "            for layer_dim1, layer_dim2 in zip(layers_dim[:-3], layers_dim[1:-2])\n",
    "        ])\n",
    "        # flatten_dim = infer_flatten_dim(conv_params, layers_dim[-3])\n",
    "        # napisz wnioskowanie spłaszczonego wymiaru\n",
    "        self.final_layer = torch.nn.Sequential(torch.nn.Linear(4096, layers_dim[-2]), torch.nn.ReLU(),\n",
    "                                               torch.nn.Linear(layers_dim[-2], layers_dim[-1]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.final_layer(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers_dim):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.ModuleList([\n",
    "            torch.nn.Sequential(torch.nn.Linear(hidden_dim1, hidden_dim2), torch.nn.ReLU())\n",
    "            for hidden_dim1, hidden_dim2 in zip(layers_dim[:-2], layers_dim[1:-1])\n",
    "        ])\n",
    "        self.final_layer = torch.nn.Linear(layers_dim[-2], layers_dim[-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.flatten(start_dim=1)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.final_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN([3, 64, 128, 128, 128, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (blocks): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (final_layer): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4096\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=os.environ['CIFAR10_PATH'], train=False,\n",
    "                                        download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=8)\n",
    "\n",
    "model = SimpleCNN([3, 32, 64, 128, 10])\n",
    "\n",
    "inputs, targets = next(iter(testloader))\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hessian_comp = hessian(model, criterion, dataloader=testloader, cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.2514059543609619]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_eigenvalues, _ = hessian_comp.eigenvalues(5)\n",
    "top_eigenvalues\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.13655626773834229, -9.76462459564209]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace = hessian_comp.trace()\n",
    "trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 3, 32, 32])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m hessian_comp \u001b[39m=\u001b[39m hessian(\n\u001b[1;32m      2\u001b[0m             model, criterion\u001b[39m=\u001b[39mcriterion, dataloader\u001b[39m=\u001b[39mdata, cuda\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      3\u001b[0m         )\n\u001b[0;32m----> 4\u001b[0m top_eigenvalues, _ \u001b[39m=\u001b[39m hessian_comp\u001b[39m.\u001b[39;49meigenvalues()\n\u001b[1;32m      5\u001b[0m trace \u001b[39m=\u001b[39m hessian_comp\u001b[39m.\u001b[39mtrace()\n",
      "File \u001b[0;32m~/anaconda3/envs/fp2/lib/python3.10/site-packages/pyhessian/hessian.py:139\u001b[0m, in \u001b[0;36mhessian.eigenvalues\u001b[0;34m(self, maxIter, tol, top_n)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m    138\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfull_dataset:\n\u001b[0;32m--> 139\u001b[0m     tmp_eigenvalue, Hv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataloader_hv_product(v)\n\u001b[1;32m    140\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    141\u001b[0m     Hv \u001b[39m=\u001b[39m hessian_vector_product(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgradsH, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams, v)\n",
      "File \u001b[0;32m~/anaconda3/envs/fp2/lib/python3.10/site-packages/pyhessian/hessian.py:88\u001b[0m, in \u001b[0;36mhessian.dataloader_hv_product\u001b[0;34m(self, v)\u001b[0m\n\u001b[1;32m     84\u001b[0m num_data \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m  \u001b[39m# count the number of datum points in the dataloader\u001b[39;00m\n\u001b[1;32m     86\u001b[0m THv \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mzeros(p\u001b[39m.\u001b[39msize())\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams\n\u001b[1;32m     87\u001b[0m       ]  \u001b[39m# accumulate result\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m \u001b[39mfor\u001b[39;00m inputs, targets \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata:\n\u001b[1;32m     89\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     90\u001b[0m     tmp_num_data \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "hessian_comp = hessian(\n",
    "            model, criterion=criterion, dataloader=data, cuda=False\n",
    "        )\n",
    "top_eigenvalues, _ = hessian_comp.eigenvalues()\n",
    "trace = hessian_comp.trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hessian()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.autograd.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(inputs, targets):\n",
    "    outputs = model(inputs)\n",
    "    loss = F.cross_entropy(outputs, targets)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "only Tensors of floating point dtype can require gradients",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m F\u001b[39m.\u001b[39;49mhessian(compute_loss, (inputs, targets))\n",
      "File \u001b[0;32m~/anaconda3/envs/fp2/lib/python3.10/site-packages/torch/autograd/functional.py:826\u001b[0m, in \u001b[0;36mhessian\u001b[0;34m(func, inputs, create_graph, strict, vectorize, outer_jacobian_strategy)\u001b[0m\n\u001b[1;32m    823\u001b[0m     _check_requires_grad(jac, \u001b[39m\"\u001b[39m\u001b[39mjacobian\u001b[39m\u001b[39m\"\u001b[39m, strict\u001b[39m=\u001b[39mstrict)\n\u001b[1;32m    824\u001b[0m     \u001b[39mreturn\u001b[39;00m jac\n\u001b[0;32m--> 826\u001b[0m res \u001b[39m=\u001b[39m jacobian(jac_func, inputs, create_graph\u001b[39m=\u001b[39;49mcreate_graph, strict\u001b[39m=\u001b[39;49mstrict, vectorize\u001b[39m=\u001b[39;49mvectorize,\n\u001b[1;32m    827\u001b[0m                strategy\u001b[39m=\u001b[39;49mouter_jacobian_strategy)\n\u001b[1;32m    828\u001b[0m \u001b[39mreturn\u001b[39;00m _tuple_postprocess(res, (is_inputs_tuple, is_inputs_tuple))\n",
      "File \u001b[0;32m~/anaconda3/envs/fp2/lib/python3.10/site-packages/torch/autograd/functional.py:589\u001b[0m, in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39menable_grad():\n\u001b[1;32m    588\u001b[0m     is_inputs_tuple, inputs \u001b[39m=\u001b[39m _as_tuple(inputs, \u001b[39m\"\u001b[39m\u001b[39minputs\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mjacobian\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 589\u001b[0m     inputs \u001b[39m=\u001b[39m _grad_preprocess(inputs, create_graph\u001b[39m=\u001b[39;49mcreate_graph, need_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    591\u001b[0m     outputs \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39minputs)\n\u001b[1;32m    592\u001b[0m     is_outputs_tuple, outputs \u001b[39m=\u001b[39m _as_tuple(outputs,\n\u001b[1;32m    593\u001b[0m                                           \u001b[39m\"\u001b[39m\u001b[39moutputs of the user-provided function\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    594\u001b[0m                                           \u001b[39m\"\u001b[39m\u001b[39mjacobian\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/fp2/lib/python3.10/site-packages/torch/autograd/functional.py:80\u001b[0m, in \u001b[0;36m_grad_preprocess\u001b[0;34m(inputs, create_graph, need_graph)\u001b[0m\n\u001b[1;32m     78\u001b[0m             res\u001b[39m.\u001b[39mappend(inp\u001b[39m.\u001b[39mclone())\n\u001b[1;32m     79\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 80\u001b[0m         res\u001b[39m.\u001b[39mappend(inp\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mrequires_grad_(need_graph))\n\u001b[1;32m     81\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(res)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: only Tensors of floating point dtype can require gradients"
     ]
    }
   ],
   "source": [
    "F.hessian(compute_loss, (inputs, targets))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenthings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hessian-eigenthings\n",
      "  Cloning https://github.com/noahgolmant/pytorch-hessian-eigenthings.git (to revision master) to /tmp/pip-install-25m0sk0w/hessian-eigenthings_3238bbb9fe6b47778d3bf674cebe7273\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/noahgolmant/pytorch-hessian-eigenthings.git /tmp/pip-install-25m0sk0w/hessian-eigenthings_3238bbb9fe6b47778d3bf674cebe7273\n",
      "  Resolved https://github.com/noahgolmant/pytorch-hessian-eigenthings.git to commit dce2e54a19963b0dfa41b93f531fb7742d46ea04\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=0.14 in /raid/NFS_SHARE/home/bartlomiej.krzepkowski/anaconda3/envs/fp2/lib/python3.10/site-packages (from hessian-eigenthings) (1.23.5)\n",
      "Requirement already satisfied: torch>=0.4 in /raid/NFS_SHARE/home/bartlomiej.krzepkowski/anaconda3/envs/fp2/lib/python3.10/site-packages (from hessian-eigenthings) (2.0.0)\n",
      "Collecting scipy>=1.2.1\n",
      "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /raid/NFS_SHARE/home/bartlomiej.krzepkowski/anaconda3/envs/fp2/lib/python3.10/site-packages (from torch>=0.4->hessian-eigenthings) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /raid/NFS_SHARE/home/bartlomiej.krzepkowski/anaconda3/envs/fp2/lib/python3.10/site-packages (from torch>=0.4->hessian-eigenthings) (4.4.0)\n",
      "Requirement already satisfied: sympy in /raid/NFS_SHARE/home/bartlomiej.krzepkowski/anaconda3/envs/fp2/lib/python3.10/site-packages (from torch>=0.4->hessian-eigenthings) (1.11.1)\n",
      "Requirement already satisfied: networkx in /raid/NFS_SHARE/home/bartlomiej.krzepkowski/anaconda3/envs/fp2/lib/python3.10/site-packages (from torch>=0.4->hessian-eigenthings) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /raid/NFS_SHARE/home/bartlomiej.krzepkowski/anaconda3/envs/fp2/lib/python3.10/site-packages (from torch>=0.4->hessian-eigenthings) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /raid/NFS_SHARE/home/bartlomiej.krzepkowski/anaconda3/envs/fp2/lib/python3.10/site-packages (from jinja2->torch>=0.4->hessian-eigenthings) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /raid/NFS_SHARE/home/bartlomiej.krzepkowski/anaconda3/envs/fp2/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy->torch>=0.4->hessian-eigenthings) (1.2.1)\n",
      "Building wheels for collected packages: hessian-eigenthings\n",
      "  Building wheel for hessian-eigenthings (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hessian-eigenthings: filename=hessian_eigenthings-0.0.2-py3-none-any.whl size=9643 sha256=b1c5d6cfaf7365c76cf8db36dbae4a1da8c59306db08e950857f31f8642ab5b7\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-xm2pynwz/wheels/60/2d/6d/59e328223a76c9697741b51a5087f062fa8f9bc2a0199dd967\n",
      "Successfully built hessian-eigenthings\n",
      "Installing collected packages: scipy, hessian-eigenthings\n",
      "Successfully installed hessian-eigenthings-0.0.2 scipy-1.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade git+https://github.com/noahgolmant/pytorch-hessian-eigenthings.git@master#egg=hessian-eigenthings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hessian_eigenthings import compute_hessian_eigenthings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=============================================================>...]  Step: 17s512ms | Tot: 5m31s | power iter error: 0.02 20/20   2/20 \n"
     ]
    }
   ],
   "source": [
    "eigenvals, eigenvecs = compute_hessian_eigenthings(model, testloader,\n",
    "                                                   criterion, 1,use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.11508816])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m eigenvals, eigenvecs \u001b[39m=\u001b[39m compute_hessian_eigenthings(model, testloader,\n\u001b[1;32m      2\u001b[0m                                                    criterion, \u001b[39m1\u001b[39;49m,use_gpu\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlanczos\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/fp2/lib/python3.10/site-packages/hessian_eigenthings/__init__.py:72\u001b[0m, in \u001b[0;36mcompute_hessian_eigenthings\u001b[0;34m(model, dataloader, loss, num_eigenthings, full_dataset, mode, use_gpu, fp16, max_possible_gpu_samples, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m     eigenvals, eigenvecs \u001b[39m=\u001b[39m deflated_power_iteration(\n\u001b[1;32m     69\u001b[0m         hvp_operator, num_eigenthings, use_gpu\u001b[39m=\u001b[39muse_gpu, fp16\u001b[39m=\u001b[39mfp16, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m     70\u001b[0m     )\n\u001b[1;32m     71\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlanczos\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 72\u001b[0m     eigenvals, eigenvecs \u001b[39m=\u001b[39m lanczos(\n\u001b[1;32m     73\u001b[0m         hvp_operator, num_eigenthings, use_gpu\u001b[39m=\u001b[39;49muse_gpu, fp16\u001b[39m=\u001b[39;49mfp16, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m     74\u001b[0m     )\n\u001b[1;32m     75\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnsupported mode \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (must be power_iter or lanczos)\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m mode)\n",
      "File \u001b[0;32m~/anaconda3/envs/fp2/lib/python3.10/site-packages/hessian_eigenthings/lanczos.py:90\u001b[0m, in \u001b[0;36mlanczos\u001b[0;34m(operator, num_eigenthings, which, max_steps, tol, num_lanczos_vectors, init_vec, use_gpu, fp16)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m init_vec \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m     init_vec \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrand(size)\n\u001b[0;32m---> 90\u001b[0m eigenvals, eigenvecs \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39;49meigsh(\n\u001b[1;32m     91\u001b[0m     A\u001b[39m=\u001b[39;49mscipy_op,\n\u001b[1;32m     92\u001b[0m     k\u001b[39m=\u001b[39;49mnum_eigenthings,\n\u001b[1;32m     93\u001b[0m     which\u001b[39m=\u001b[39;49mwhich,\n\u001b[1;32m     94\u001b[0m     maxiter\u001b[39m=\u001b[39;49mmax_steps,\n\u001b[1;32m     95\u001b[0m     tol\u001b[39m=\u001b[39;49mtol,\n\u001b[1;32m     96\u001b[0m     ncv\u001b[39m=\u001b[39;49mnum_lanczos_vectors,\n\u001b[1;32m     97\u001b[0m     return_eigenvectors\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     98\u001b[0m )\n\u001b[1;32m     99\u001b[0m \u001b[39mreturn\u001b[39;00m eigenvals, eigenvecs\u001b[39m.\u001b[39mT\n",
      "File \u001b[0;32m~/anaconda3/envs/fp2/lib/python3.10/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:1697\u001b[0m, in \u001b[0;36meigsh\u001b[0;34m(A, k, M, sigma, which, v0, ncv, maxiter, tol, return_eigenvectors, Minv, OPinv, mode)\u001b[0m\n\u001b[1;32m   1695\u001b[0m \u001b[39mwith\u001b[39;00m _ARPACK_LOCK:\n\u001b[1;32m   1696\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m params\u001b[39m.\u001b[39mconverged:\n\u001b[0;32m-> 1697\u001b[0m         params\u001b[39m.\u001b[39;49miterate()\n\u001b[1;32m   1699\u001b[0m     \u001b[39mreturn\u001b[39;00m params\u001b[39m.\u001b[39mextract(return_eigenvectors)\n",
      "File \u001b[0;32m~/anaconda3/envs/fp2/lib/python3.10/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:549\u001b[0m, in \u001b[0;36m_SymmetricArpackParams.iterate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mido \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    547\u001b[0m     \u001b[39m# compute y = Op*x\u001b[39;00m\n\u001b[1;32m    548\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 549\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkd[yslice] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mOP(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mworkd[xslice])\n\u001b[1;32m    550\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    551\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkd[xslice] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mOPb(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkd[xslice])\n",
      "File \u001b[0;32m~/anaconda3/envs/fp2/lib/python3.10/site-packages/scipy/sparse/linalg/_interface.py:232\u001b[0m, in \u001b[0;36mLinearOperator.matvec\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m (N,) \u001b[39mand\u001b[39;00m x\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m (N,\u001b[39m1\u001b[39m):\n\u001b[1;32m    230\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mdimension mismatch\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 232\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_matvec(x)\n\u001b[1;32m    234\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, np\u001b[39m.\u001b[39mmatrix):\n\u001b[1;32m    235\u001b[0m     y \u001b[39m=\u001b[39m asmatrix(y)\n",
      "File \u001b[0;32m~/anaconda3/envs/fp2/lib/python3.10/site-packages/scipy/sparse/linalg/_interface.py:530\u001b[0m, in \u001b[0;36m_CustomLinearOperator._matvec\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_matvec\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__matvec_impl(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/fp2/lib/python3.10/site-packages/hessian_eigenthings/lanczos.py:81\u001b[0m, in \u001b[0;36mlanczos.<locals>._scipy_apply\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39mif\u001b[39;00m use_gpu:\n\u001b[1;32m     80\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m---> 81\u001b[0m out \u001b[39m=\u001b[39m operator\u001b[39m.\u001b[39;49mapply(x)\n\u001b[1;32m     82\u001b[0m out \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mmaybe_fp16(out, fp16)\n\u001b[1;32m     83\u001b[0m out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/anaconda3/envs/fp2/lib/python3.10/site-packages/hessian_eigenthings/hvp_operator.py:63\u001b[0m, in \u001b[0;36mHVPOperator.apply\u001b[0;34m(self, vec)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39mReturns H*vec where H is the hessian of the loss w.r.t.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39mthe vectorized model parameters\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfull_dataset:\n\u001b[0;32m---> 63\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply_full(vec)\n\u001b[1;32m     64\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_batch(vec)\n",
      "File \u001b[0;32m~/anaconda3/envs/fp2/lib/python3.10/site-packages/hessian_eigenthings/hvp_operator.py:94\u001b[0m, in \u001b[0;36mHVPOperator._apply_full\u001b[0;34m(self, vec)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n\u001b[1;32m     93\u001b[0m     \u001b[39mif\u001b[39;00m hessian_vec_prod \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m         hessian_vec_prod \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply_batch(vec)\n\u001b[1;32m     95\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     96\u001b[0m         hessian_vec_prod \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_batch(vec)\n",
      "File \u001b[0;32m~/anaconda3/envs/fp2/lib/python3.10/site-packages/hessian_eigenthings/hvp_operator.py:73\u001b[0m, in \u001b[0;36mHVPOperator._apply_batch\u001b[0;34m(self, vec)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39m# compute original gradient, tracking computation graph\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_zero_grad()\n\u001b[0;32m---> 73\u001b[0m grad_vec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_grad()\n\u001b[1;32m     74\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_zero_grad()\n\u001b[1;32m     75\u001b[0m \u001b[39m# take the second gradient\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[39m# this is the derivative of <grad_vec, v> where <,> is an inner product.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fp2/lib/python3.10/site-packages/hessian_eigenthings/hvp_operator.py:135\u001b[0m, in \u001b[0;36mHVPOperator._prepare_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(\u001b[39minput\u001b[39m)\n\u001b[1;32m    134\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(output, target)\n\u001b[0;32m--> 135\u001b[0m grad_dict \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mgrad(\n\u001b[1;32m    136\u001b[0m     loss, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mparameters(), create_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    137\u001b[0m )\n\u001b[1;32m    138\u001b[0m \u001b[39mif\u001b[39;00m grad_vec \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     grad_vec \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([g\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m grad_dict])\n",
      "File \u001b[0;32m~/anaconda3/envs/fp2/lib/python3.10/site-packages/torch/autograd/__init__.py:303\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[39mreturn\u001b[39;00m _vmap_internals\u001b[39m.\u001b[39m_vmap(vjp, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, allow_none_pass_through\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[1;32m    302\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 303\u001b[0m     \u001b[39mreturn\u001b[39;00m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    304\u001b[0m         t_outputs, grad_outputs_, retain_graph, create_graph, t_inputs,\n\u001b[1;32m    305\u001b[0m         allow_unused, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eigenvals, eigenvecs = compute_hessian_eigenthings(model, testloader,\n",
    "                                                   criterion, 1,use_gpu=False, mode='lanczos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
