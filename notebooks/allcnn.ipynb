{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AllCNN(torch.nn.Module):\n",
    "    def __init__(self, base_dim: int, exponents: List[int], activation_name: str, num_class: int):\n",
    "        super().__init__()\n",
    "        self.first = torch.nn.Sequential(torch.nn.Conv2d(3, base_dim, 3, padding=1, bias=False),\n",
    "                                         torch.nn.BatchNorm2d(base_dim),\n",
    "                                         torch.nn.ReLU())\n",
    "        self.blocks = torch.nn.ModuleList([\n",
    "            torch.nn.Sequential(torch.nn.Conv2d(base_dim*2**i, base_dim*2**i, 3, padding=1, bias=False),\n",
    "                                torch.nn.BatchNorm2d(base_dim*2**i),\n",
    "                                torch.nn.ReLU(),\n",
    "                                torch.nn.Conv2d(base_dim*2**i, base_dim*2**(i+1), 3, padding=1, bias=False, stride=2),\n",
    "                                torch.nn.BatchNorm2d(base_dim*2**(i+1)),\n",
    "                                torch.nn.ReLU())\n",
    "                        for i in exponents])\n",
    "        last_exp = exponents[-1] + 1\n",
    "        self.final_layer = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(base_dim*2**last_exp, base_dim*2**last_exp, 3, padding=1, bias=False),\n",
    "            torch.nn.BatchNorm2d(base_dim*2**last_exp),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(base_dim*2**last_exp, base_dim*2**last_exp, 1, padding=0, bias=False),\n",
    "            torch.nn.BatchNorm2d(base_dim*2**last_exp),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(base_dim*2**last_exp, num_class, 1, padding=0, bias=False))\n",
    "        self.avg = torch.nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.final_layer(x)\n",
    "        x = self.avg(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m AllCNN(base_dim\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, exponents\u001b[39m=\u001b[39;49m[], activation_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, num_class\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m, in \u001b[0;36mAllCNN.__init__\u001b[0;34m(self, base_dim, exponents, activation_name, num_class)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfirst \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mSequential(torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mConv2d(\u001b[39m3\u001b[39m, base_dim, \u001b[39m3\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, bias\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m),\n\u001b[1;32m      5\u001b[0m                                  torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mBatchNorm2d(base_dim),\n\u001b[1;32m      6\u001b[0m                                  torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mReLU())\n\u001b[1;32m      7\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModuleList([\n\u001b[1;32m      8\u001b[0m     torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mSequential(torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mConv2d(base_dim\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mi, base_dim\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mi, \u001b[39m3\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, bias\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m),\n\u001b[1;32m      9\u001b[0m                         torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mBatchNorm2d(base_dim\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mi),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m                         torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mReLU())\n\u001b[1;32m     14\u001b[0m                 \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m exponents])\n\u001b[0;32m---> 15\u001b[0m last_exp \u001b[39m=\u001b[39m exponents[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m] \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_layer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mSequential(\n\u001b[1;32m     17\u001b[0m     torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mConv2d(base_dim\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mlast_exp, base_dim\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mlast_exp, \u001b[39m3\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, bias\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m),\n\u001b[1;32m     18\u001b[0m     torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mBatchNorm2d(base_dim\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mlast_exp),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mReLU(),\n\u001b[1;32m     23\u001b[0m     torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mConv2d(base_dim\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mlast_exp, num_class, \u001b[39m1\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, bias\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n\u001b[1;32m     24\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavg \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mAdaptiveAvgPool2d(\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "model = AllCNN(base_dim=32, exponents=[], activation_name='relu', num_class=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(1, 3, 32, 32)).squeeze([-1, -2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AllCNN(\n",
       "  (first): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (final_layer): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(64, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (avg): AdaptiveAvgPool2d(output_size=1)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
